{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# OPC UA a SQLite (Nuevo Esquema - 12 Variables)\n",
                "\n",
                "Este notebook se conecta al PLC mediante `asyncua`, busca las 12 variables principales del MES, y las inserta periódicamente en la base de datos `datos.db`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import asyncio\n",
                "import sqlite3\n",
                "import logging\n",
                "import os\n",
                "from datetime import datetime\n",
                "from asyncua import Client\n",
                "\n",
                "# Configuraciones OPC UA\n",
                "ENDPOINT = \"opc.tcp://192.168.0.20:4840\"\n",
                "DB_PATH = \"../database/datos.db\"\n",
                "DB_NAME = \"MES\"\n",
                "\n",
                "# Nombres de las 12 variables a buscar (Pascal_Case)\n",
                "VAR_NAMES = [\n",
                "    \"Machine_State\", \"Heartbeat\", \"Target_Speed\", \"Total_Parts_Produced\",\n",
                "    \"Parts_OK\", \"Parts_NOK\", \"Last_Cycle_Time\", \"Availability\",\n",
                "    \"Perfomance\", \"Quality\", \"Initial_Timestamp\", \"Final_Timestamp\"\n",
                "]\n",
                "\n",
                "logging.basicConfig(level=logging.INFO)\n",
                "_logger = logging.getLogger('opcua_sqlite')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Inicializar Base de Datos\n",
                "Aseguramos que existe el directorio y creamos la tabla con los 12 campos nuevos."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def init_db():\n",
                "    os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)\n",
                "    conn = sqlite3.connect(DB_PATH)\n",
                "    cursor = conn.cursor()\n",
                "    \n",
                "    # Creamos la tabla adaptada al nuevo esquema (usando los nombres oficiales)\n",
                "    cursor.execute('''\n",
                "        CREATE TABLE IF NOT EXISTS mes_data (\n",
                "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
                "            db_timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
                "            Machine_State INTEGER,\n",
                "            Heartbeat INTEGER,\n",
                "            Target_Speed REAL,\n",
                "            Total_Parts_Produced INTEGER,\n",
                "            Parts_OK INTEGER,\n",
                "            Parts_NOK INTEGER,\n",
                "            Last_Cycle_Time REAL,\n",
                "            Availability REAL,\n",
                "            Perfomance REAL,\n",
                "            Quality REAL,\n",
                "            Initial_Timestamp TEXT,\n",
                "            Final_Timestamp TEXT\n",
                "        )\n",
                "    ''')\n",
                "    conn.commit()\n",
                "    return conn\n",
                "\n",
                "conn = init_db()\n",
                "_logger.info(f\"Base de datos conectada en {DB_PATH}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Helper para buscar nodos\n",
                "Función recursiva para encontrar nodos dentro de la carpeta Objects por su BrowseName."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "async def find_node_by_name(client, db_name, var_name, max_depth=5):\n",
                "    objects = client.nodes.objects\n",
                "    \n",
                "    async def walk(node, depth):\n",
                "        if depth > max_depth: return None\n",
                "        try: children = await node.get_children()\n",
                "        except: return None\n",
                "        \n",
                "        for child in children:\n",
                "            try: bname = (await child.read_browse_name()).Name\n",
                "            except: continue\n",
                "            \n",
                "            if bname == db_name:\n",
                "                db_children = await child.get_children()\n",
                "                for var in db_children:\n",
                "                    if (await var.read_browse_name()).Name == var_name:\n",
                "                        return var\n",
                "            \n",
                "            found = await walk(child, depth + 1)\n",
                "            if found: return found\n",
                "        return None\n",
                "    return await walk(objects, 0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Bucle Principal Asíncrono OPC UA\n",
                "Conectamos, localizamos los 12 nodos e insertamos continuamente."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "async def main_loop():\n",
                "    _logger.info(f\"Conectando a {ENDPOINT}...\")\n",
                "    async with Client(url=ENDPOINT) as client:\n",
                "        _logger.info(\"Conectado a OPC UA.\")\n",
                "        \n",
                "        # 1. Resolver los 12 nodos OPC UA\n",
                "        _logger.info(\"Resolviendo Nodos...\")\n",
                "        nodes = {}\n",
                "        for vname in VAR_NAMES:\n",
                "            node = await find_node_by_name(client, DB_NAME, vname)\n",
                "            if getattr(node, 'nodeid', None):\n",
                "                nodes[vname] = node\n",
                "                # _logger.info(f\"Encontrado {vname}: {node.nodeid}\")\n",
                "            else:\n",
                "                _logger.error(f\"No se encontró la variable: {vname}\")\n",
                "        \n",
                "        if len(nodes) < len(VAR_NAMES):\n",
                "            _logger.error(\"Faltan nodos. Deteniendo el script para revisar la nomenclatura.\")\n",
                "            return\n",
                "            \n",
                "        _logger.info(\"Todos los nodos encontrados. --- INICIANDO LECTURA E INSERCIÓN ---\")\n",
                "        \n",
                "        cursor = conn.cursor()\n",
                "        \n",
                "        try:\n",
                "            while True:\n",
                "                # Leer todos los valores en un dict comprehension\n",
                "                values = {name: await node.read_value() for name, node in nodes.items()}\n",
                "                \n",
                "                # Preparar sentencia SQL (12 interrogantes para las 12 vars)\n",
                "                placeholders = \", \".join([\"?\"] * len(VAR_NAMES))\n",
                "                columns = \", \".join(VAR_NAMES)\n",
                "                \n",
                "                query = f\"INSERT INTO mes_data ({columns}) VALUES ({placeholders})\"\n",
                "                \n",
                "                # Tupla ordenada con los valores leídos para insertar en SQLite\n",
                "                data_tuple = tuple(values[v] for v in VAR_NAMES)\n",
                "                \n",
                "                cursor.execute(query, data_tuple)\n",
                "                conn.commit()\n",
                "                \n",
                "                # Print amigable (mostrando solo 4 métricas clave en consola para no ensuciar)\n",
                "                print(f\"[SQL Insert] HB:{values['Heartbeat']} | ST:{values['Machine_State']} | Spd:{values['Target_Speed']:.1f} | Prod:{values['Total_Parts_Produced']} | OEE:{values['Perfomance']*100:.1f}%\")\n",
                "                \n",
                "                await asyncio.sleep(1.0) # Ciclo de captura de 1s\n",
                "                \n",
                "        except asyncio.CancelledError:\n",
                "            _logger.info(\"Lectura detenida por el usuario.\")\n",
                "            \n",
                "try:\n",
                "    task = asyncio.create_task(main_loop())\n",
                "    await task\n",
                "except KeyboardInterrupt:\n",
                "    task.cancel()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Consultar resultados con Pandas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Leemos la tabla entera de SQLite y la ponemos en un DataFrame\n",
                "df = pd.read_sql_query(\"SELECT * FROM mes_data ORDER BY id DESC LIMIT 10\", conn)\n",
                "\n",
                "print(\"Últimos 10 registros en SQLite:\")\n",
                "display(df)"
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python",
            "version": "3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}